[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "MP01 – Netflix",
    "section": "",
    "text": "Code\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n    dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\n\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                  destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\n\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                  destfile=COUNTRY_TOP_10_FILENAME)\n}\nCode\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(janitor)\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nCode\nglobal_path  &lt;- \"data/mp01/global_top10_alltime.csv\"\ncountry_path &lt;- \"data/mp01/country_top10_alltime.csv\"\n\nglobal_df  &lt;- read_tsv(global_path,  show_col_types = FALSE) |&gt; clean_names()\ncountry_df &lt;- read_tsv(country_path, show_col_types = FALSE) |&gt; clean_names()\n\ncat(\"Global rows:\", nrow(global_df), \"  Country rows:\", nrow(country_df), \"\\n\")\n\n\nGlobal rows: 8880   Country rows: 413620 \n\n\nCode\ndplyr::glimpse(global_df)\n\n\nRows: 8,880\nColumns: 9\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films (English)\", \"Films (English)\", \"Film…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"KPop Demon Hunters\", \"Ruth & Boaz\", \"The W…\n$ season_title               &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"…\n$ weekly_hours_viewed        &lt;dbl&gt; 32200000, 15900000, 13500000, 15700000, 112…\n$ runtime                    &lt;dbl&gt; 1.6667, 1.5500, 1.7833, 2.4333, 1.8333, 1.7…\n$ weekly_views               &lt;dbl&gt; 19300000, 10300000, 7600000, 6500000, 61000…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 15, 1, 3, 5, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, …\nCode\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\nCode\n# Import and clean GLOBAL_TOP_10\nGLOBAL_TOP_10 &lt;- read_tsv(GLOBAL_TOP_10_FILENAME, show_col_types = FALSE) %&gt;%\n  mutate(season_title = if_else(season_title == \"N/A\", NA_character_, season_title))\n\n# Import and clean COUNTRY_TOP_10\nCOUNTRY_TOP_10 &lt;- read_tsv(COUNTRY_TOP_10_FILENAME, na = \"N/A\", show_col_types = FALSE)\n\n# Quick checks\nglimpse(GLOBAL_TOP_10)\n\n\nRows: 8,880\nColumns: 9\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films (English)\", \"Films (English)\", \"Film…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"KPop Demon Hunters\", \"Ruth & Boaz\", \"The W…\n$ season_title               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"aka Ch…\n$ weekly_hours_viewed        &lt;dbl&gt; 32200000, 15900000, 13500000, 15700000, 112…\n$ runtime                    &lt;dbl&gt; 1.6667, 1.5500, 1.7833, 2.4333, 1.8333, 1.7…\n$ weekly_views               &lt;dbl&gt; 19300000, 10300000, 7600000, 6500000, 61000…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 15, 1, 3, 5, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, …\n\n\nCode\nglimpse(COUNTRY_TOP_10)\n\n\nRows: 413,620\nColumns: 8\n$ country_name               &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Arg…\n$ country_iso2               &lt;chr&gt; \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"…\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films\", \"Films\", \"Films\", \"Films\", \"Films\"…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"Sonic the Hedgehog 3\", \"KPop Demon Hunters…\n$ season_title               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Bi…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 2, 15, 1, 2, 1, 1, 2, 5, 1, 2, 2, 1, 1, 1, …"
  },
  {
    "objectID": "mp01.html#initial-data-exploration",
    "href": "mp01.html#initial-data-exploration",
    "title": "MP01 – Netflix",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\nIn this section, we perform a first exploration of the global Netflix Top 10 dataset. Our goal is to understand the size of the dataset, the distribution of categories, and the diversity of programming represented.\n\n\nCode\nlibrary(dplyr)\nlibrary(gt)\n\n# total\ntotal_rows &lt;- nrow(GLOBAL_TOP_10)\nunique_shows &lt;- n_distinct(GLOBAL_TOP_10$show_title)\n\n# category\ncategory_summary &lt;- GLOBAL_TOP_10 %&gt;%\n  count(category, sort = TRUE)\n\ncategory_summary %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Table 1: Number of Records by Category in Global Top 10\")\n\n\n\n\n\n\n\n\nTable 1: Number of Records by Category in Global Top 10\n\n\ncategory\nn\n\n\n\n\nFilms (English)\n2220\n\n\nFilms (Non-English)\n2220\n\n\nTV (English)\n2220\n\n\nTV (Non-English)\n2220\n\n\n\n\n\n\n\nCode\n    category_summary %&gt;%\n  gt() %&gt;%\n  tab_style(\n    style = cell_fill(color = \"#ffe5e5\"),\n    locations = cells_body(\n      rows = category == \"TV (English)\"\n    )\n  )\n\n\n\n\n\n\n\n\ncategory\nn\n\n\n\n\nFilms (English)\n2220\n\n\nFilms (Non-English)\n2220\n\n\nTV (English)\n2220\n\n\nTV (Non-English)\n2220"
  },
  {
    "objectID": "mp01.html#interpretation",
    "href": "mp01.html#interpretation",
    "title": "MP01 – Netflix",
    "section": "Interpretation:",
    "text": "Interpretation:\nThe global dataset contains r total_rows weekly records, covering r unique_shows unique shows. As shown in Table 1, the four categories — English and non-English films and TV — are evenly represented, each with 2,220 entries. This balance is a feature of the dataset’s construction, ensuring comparability across categories. In practice, however, actual viewer attention may be concentrated in a smaller number of titles.\n\n\nCode\nstranger_things &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(grepl(\"Stranger Things\", show_title))\n\ntotal_hours &lt;- sum(stranger_things$weekly_hours_viewed, na.rm = TRUE)\n\nweeks_in_top10 &lt;- n_distinct(stranger_things$week)\n\nst_countries &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(grepl(\"Stranger Things\", show_title)) %&gt;%\n  summarise(num_countries = n_distinct(country_name)) %&gt;%\n  pull(num_countries)\n\ntop_english_tv &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(category == \"TV (English)\") %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_hours)) %&gt;%\n  slice(1:5)\n\ntop_english_tv\n\n\n# A tibble: 5 × 2\n  show_title      total_hours\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Stranger Things  2967980000\n2 Wednesday        2876350000\n3 Bridgerton       2279710000\n4 Ginny & Georgia  1556880000\n5 You              1542990000"
  },
  {
    "objectID": "mp01.html#press-release-1-stranger-things-season-5",
    "href": "mp01.html#press-release-1-stranger-things-season-5",
    "title": "MP01 – Netflix",
    "section": "Press Release 1: Stranger Things Season 5",
    "text": "Press Release 1: Stranger Things Season 5\n\nNetflix’s Global Phenomenon Returns: Stranger Things Prepares for a Historic Final Season\nThe countdown is on—Stranger Things will return in late 2025 with its fifth and final season, marking the end of a show that has defined a generation of Netflix storytelling. As the series prepares to close its chapter, Netflix looks back at the extraordinary success that made Hawkins, Indiana, and the Upside Down household names around the world.\nSince its launch in 2016, Stranger Things has become a cultural phenomenon and one of Netflix’s flagship originals. Across four groundbreaking seasons, the series has accumulated more than r scales::comma(total_hours) hours of global viewership, securing its place among the most-watched English-language shows on the platform. These numbers reflect not just statistics, but years of thrilling storytelling enjoyed by millions of fans across continents.\nWhat sets Stranger Things apart is its ability to hold audience attention over time. The series has remained in the Top 10 for more than r weeks_in_top10 weeks, demonstrating a remarkable staying power that few titles can match. Week after week, season after season, the adventures of Eleven and her friends have kept viewers eagerly returning.\nThe show’s reach has also been distinctly international. Appearing in the Top 10 across r st_countries countries, Stranger Things has proven that a story born in small-town America resonates with audiences from Buenos Aires to Berlin, from Seoul to Sydney. This global impact underscores Netflix’s mission to deliver entertainment without borders.\nWhen compared to other top English-language TV series, Stranger Things consistently ranks near the top in total hours viewed. While acclaimed titles such as r top_english_tv$show_title[2] and r top_english_tv$show_title[3] have drawn large audiences, Stranger Things continues to outpace many of its peers, highlighting its singular role as a genre-defining show that blends supernatural thrills with heartfelt nostalgia.\nAs the final season approaches, Netflix is excited to deliver a powerful conclusion to this global success story. With its unique mix of suspense, 1980s nostalgia, and unforgettable characters, Stranger Things is ready to leave an indelible mark on television history one last time.\n\n\nCode\n# Stranger Things trend\nlibrary(ggplot2)\n\nst_data &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(grepl(\"Stranger Things\", show_title)) %&gt;%\n  group_by(week) %&gt;%\n  summarise(weekly_hours = sum(weekly_hours_viewed, na.rm = TRUE))\n\nggplot(st_data, aes(x = week, y = weekly_hours/1e6)) +\n  geom_line(color = \"#e50914\", size = 1.2) +\n  geom_point(color = \"#e50914\") +\n  labs(\n    title = \"Stranger Things Global Viewership Trend\",\n    x = \"Week\",\n    y = \"Weekly Hours Viewed (Millions)\"\n  ) +\n  theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nCode\n# India data preparation\nindia_top &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\")\n\nindia_hours &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(show_title %in% india_top$show_title) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %&gt;%\n  pull(total_hours)\n\nindia_shows &lt;- n_distinct(india_top$show_title)\n\nus_top &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"United States\")\n\nindia_unique &lt;- setdiff(india_top$show_title, us_top$show_title)\n # hit program\n \nindia_hours\n\n\n[1] 1.04909e+11\n\n\nCode\nindia_shows\n\n\n[1] 1173\n\n\nCode\nhead(india_unique, 10)\n\n\n [1] \"Mahavatar Narsimha\"          \"Son of Sardaar 2\"           \n [3] \"Dhadak 2\"                    \"Saiyaara\"                   \n [5] \"Odum Kuthira Chadum Kuthira\" \"Inspector Zende\"            \n [7] \"Kingdom\"                     \"Maareesan\"                  \n [9] \"The Ba***ds of Bollywood\"    \"Bon Appétit, Your Majesty\""
  },
  {
    "objectID": "mp01.html#press-release-2-netflixs-blockbuster-growth-in-india",
    "href": "mp01.html#press-release-2-netflixs-blockbuster-growth-in-india",
    "title": "MP01 – Netflix",
    "section": "Press Release 2: Netflix’s Blockbuster Growth in India",
    "text": "Press Release 2: Netflix’s Blockbuster Growth in India\n\nNetflix Celebrates Record-Breaking Hindi Hits and Rapid Subscriber Growth in the World’s Largest Market\nIndia, the world’s most populous nation, has become one of Netflix’s fastest-growing regions. With the surge of high-quality Hindi-language films and TV series, Netflix has established itself as a premier destination for Indian entertainment.\nOver the past year, Hindi titles available on Netflix have generated more than r scales::comma(india_hours) hours of global viewing, showcasing the extraordinary appetite of Indian audiences for local-language content. In total, Indian subscribers have pushed r india_shows unique shows and films into the weekly Top 10 rankings.\nWhat sets India apart is the strength of titles that resonate specifically with local viewers. Shows such as r india_unique[1] and r india_unique[2] have dominated the Top 10 in India even when they did not chart in the United States. This highlights Netflix’s ability to foster regional hits that speak directly to Indian culture and tastes.\nTaken together, these viewing patterns suggest rapid subscriber growth in India. If Hindi-language viewership is treated as a proxy for the size of the Indian customer base, Netflix is now engaging millions of households across the country—making India one of the platform’s most dynamic growth markets.\nLooking ahead, Netflix will continue to invest in Hindi-language originals and expand its partnerships with Indian storytellers. By delivering compelling local hits alongside global blockbusters, Netflix is committed to ensuring that Indian audiences feel at home on the world’s leading streaming platform.\n\n\nCode\n# Top 10 Netflix shows in India by number of weeks in Top 10\nindia_top10 &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\") %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(weeks_in_top10 = n_distinct(week)) %&gt;%\n  arrange(desc(weeks_in_top10)) %&gt;%\n  slice(1:10)\n\nlibrary(ggplot2)\n\nggplot(\n  india_top10,                                    \n  aes(x = reorder(show_title, weeks_in_top10),   \n      y = weeks_in_top10)\n) +\n  geom_col(fill = \"#E50914\") +\n  coord_flip() +                                 \n  theme_minimal() +\n  labs(\n    title = \"Top 10 Netflix Shows in India by Weeks in Top 10\",\n    x = \"Show Title\",\n    y = \"Weeks in Top 10\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Non-English TV shows in GLOBAL dataset\nnon_english_tv &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(category == \"TV (Non-English)\")\n\n# total hour\nnon_eng_hours &lt;- non_english_tv %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %&gt;%\n  pull(total_hours)\n\n# TV amount\nnon_eng_shows &lt;- n_distinct(non_english_tv$show_title)\n\n# hit non-english tv shows\ntop_non_eng &lt;- non_english_tv %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE),\n            total_weeks = n_distinct(week)) %&gt;%\n  arrange(desc(total_hours)) %&gt;%\n  slice(1:5)"
  },
  {
    "objectID": "mp01.html#press-release-3-netflixs-global-non-english-tv-success",
    "href": "mp01.html#press-release-3-netflixs-global-non-english-tv-success",
    "title": "MP01 – Netflix",
    "section": "Press Release 3: Netflix’s Global Non-English TV Success",
    "text": "Press Release 3: Netflix’s Global Non-English TV Success\n\nFrom Seoul to Madrid: Non-English Originals Reshape Netflix’s Global Top 10\nNetflix today announced the remarkable worldwide success of its Non-English language TV series, which continue to capture audiences and fuel subscriber growth around the globe.\nAcross all markets, Non-English TV titles have generated more than r scales::comma(non_eng_hours) hours of global viewing, cementing their role as a cornerstone of Netflix’s content strategy. In total, over r non_eng_shows unique series have reached the Top 10, demonstrating both the popularity and diversity of storytelling outside the English-speaking world.\nBreakout hits like r top_non_eng$show_title[1] and r top_non_eng$show_title[2] have dominated the charts, proving that compelling stories transcend borders. These titles have not only topped the rankings in their home countries but also reached millions of households across dozens of international markets.\nThe rise of Non-English originals reflects a major shift in global entertainment: audiences everywhere are embracing local stories with universal appeal. For Netflix, this success highlights the value of continued investment in regional productions—from Korean dramas to Spanish thrillers—that can resonate far beyond their country of origin.\nAs Netflix expands its portfolio of Non-English hits, the company is committed to delivering more stories that connect with global audiences, no matter the language.\n\n\nCode\n# Compare English vs Non-English TV\ntv_compare &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(category %in% c(\"TV (English)\", \"TV (Non-English)\")) %&gt;%\n  group_by(category) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))\n\nggplot(tv_compare, aes(x = category, y = total_hours/1e9, fill = category)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_manual(values = c(\"#e50914\", \"#221f1f\")) +\n  labs(\n    title = \"Global Viewership: English vs Non-English TV\",\n    x = \"\",\n    y = \"Total Hours Viewed (Billions)\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xiaolin Wu — STA 9750 Website",
    "section": "",
    "text": "Welcome!\nHi, my name is Xiaolin Wu.\nThis website hosts my submission materials for STA 9750 at Baruch College.\nI am currently a graduate student with interests in data analytics and urban design.\nHere, you’ll find my course projects, assignments, and reflections.\n\n📄 My Resume\n\n📧 Contact: xiaolin.wu1@baruchmail.cuny.edu\n\n\n\n\n\n\n\n\nLast Updated: Friday 10 03, 2025 at 22:26PM"
  },
  {
    "objectID": "STA9750-2025-FALL/lab03.html",
    "href": "STA9750-2025-FALL/lab03.html",
    "title": "STA 9750 – Lab 03",
    "section": "",
    "text": "This is the Lab 03 report covering Vectors, Review, Packages, Variables, Comments, Vector Types, Functions, Control Flow, and Programming Exercises."
  },
  {
    "objectID": "STA9750-2025-FALL/lab03.html#creating-vectors",
    "href": "STA9750-2025-FALL/lab03.html#creating-vectors",
    "title": "STA 9750 – Lab 03",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nx &lt;- c(1, 3, 5, 7)\ny &lt;- 2:6\nz &lt;- seq(0, 1, by = 0.2)\nx; y; z\n\n[1] 1 3 5 7\n\n\n[1] 2 3 4 5 6\n\n\n[1] 0.0 0.2 0.4 0.6 0.8 1.0\n\n\n\nx + 1\n\n[1] 2 4 6 8\n\nx * 2\n\n[1]  2  6 10 14\n\nx + c(1, 2)   # Recycling rule\n\n[1] 2 5 6 9\n\n\n\na &lt;- 5; b &lt;- 2\na^b; a %% b; a %/% b\n\n[1] 25\n\n\n[1] 1\n\n\n[1] 2\n\n\n\nls()\n\n[1] \"a\" \"b\" \"x\" \"y\" \"z\"\n\nrm(b); ls()\n\n[1] \"a\" \"x\" \"y\" \"z\"\n\n# Use ?mean in the Console to open help; avoid putting ? in a rendered document.\n\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n\n\n# This can be slow; comment it out if your network is slow.\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nNROW(available.packages())\n\n[1] 22806\n\n\n\nhead(flights, 10)\n\n# A tibble: 10 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nmy_apples &lt;- 5\nmy_oranges &lt;- 6\nmy_fruit &lt;- my_apples + my_oranges\nmy_fruit\n\n[1] 11\n\n\n\n# This is a comment\nx &lt;- 1  # Inline comment\n\n# This line will not run:\n# y &lt;- 2\n\n\nnum  &lt;- c(1.2, 3.5)\nint  &lt;- c(1L, 2L, 3L)\nchr  &lt;- c(\"a\", \"b\")\nlgc  &lt;- c(TRUE, FALSE, NA)\n\ntypeof(num); typeof(int); typeof(chr); typeof(lgc)\n\n[1] \"double\"\n\n\n[1] \"integer\"\n\n\n[1] \"character\"\n\n\n[1] \"logical\"\n\nclass(num)\n\n[1] \"numeric\"\n\nas.numeric(chr)   # Conversion fails, produces NA\n\n[1] NA NA\n\nis.na(lgc)\n\n[1] FALSE FALSE  TRUE\n\n\n\nx &lt;- c(1, 2, NA, 4)\nmean(x, na.rm = TRUE)\n\n[1] 2.333333\n\n\n\nfahrenheit_to_celsius &lt;- function(f) {\n  (f - 32) * 5/9\n}\nfahrenheit_to_celsius(77)\n\n[1] 25\n\n\n\nn &lt;- 5\nif (n %% 2 == 0) {\n  msg &lt;- \"even\"\n} else {\n  msg &lt;- \"odd\"\n}\nmsg\n\n[1] \"odd\"\n\n\n\nout &lt;- c()\nfor (i in 1:5) {\n  out[i] &lt;- i^2\n}\nout\n\n[1]  1  4  9 16 25\n\n\n\nx &lt;- -3:3\nifelse(x &gt;= 0, \"non-negative\", \"negative\")\n\n[1] \"negative\"     \"negative\"     \"negative\"     \"non-negative\" \"non-negative\"\n[6] \"non-negative\" \"non-negative\"\n\n\n\nv &lt;- c(2, 5, NA, 9, 11)\nmean(v, na.rm = TRUE)\n\n[1] 6.75\n\nsum(v, na.rm = TRUE)\n\n[1] 27\n\nlength(v)\n\n[1] 5\n\n\n\nc_to_f &lt;- function(c) {\n  (c * 9/5) + 32\n}\nc_to_f(0)\n\n[1] 32\n\nc_to_f(20)\n\n[1] 68\n\nc_to_f(100)\n\n[1] 212\n\n\n\nflights |&gt;\n  group_by(month) |&gt;\n  summarize(mean_dep = mean(dep_delay, na.rm = TRUE)) |&gt;\n  arrange(month)\n\n# A tibble: 12 × 2\n   month mean_dep\n   &lt;int&gt;    &lt;dbl&gt;\n 1     1    10.0 \n 2     2    10.8 \n 3     3    13.2 \n 4     4    13.9 \n 5     5    13.0 \n 6     6    20.8 \n 7     7    21.7 \n 8     8    12.6 \n 9     9     6.72\n10    10     6.24\n11    11     5.44\n12    12    16.6"
  },
  {
    "objectID": "lab02.html",
    "href": "lab02.html",
    "title": "Lab 02 Practice",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n#| echo: false\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyverse)\ntxhousing |&gt; \n  filter(city==\"Houston\") |&gt; \n  group_by(year) |&gt; \n  summarize(sales=sum(sales)) |&gt; \n  ggplot(aes(x=year, y=sales)) + \n    geom_line() + \n    ggtitle(\"Annual Houses Sold in Houston, TX\")"
  },
  {
    "objectID": "lab02.html#new-element-two-columns",
    "href": "lab02.html#new-element-two-columns",
    "title": "Lab 02 Practice",
    "section": "NEW ELEMENT — Two Columns",
    "text": "NEW ELEMENT — Two Columns\n\n\n\nNotes\n\nData: txhousing\nCity: Houston\nMetric: yearly sales\n\n\n\n\n\n# A tibble: 6 × 3\n   year sales avg_price\n  &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1  2000 52459   153285.\n2  2001 53856   158590.\n3  2002 56563   167714.\n4  2003 60732   171537.\n5  2004 66979   175822.\n6  2005 72800   185497."
  },
  {
    "objectID": "STA9750-2025-FALL/lab02.html",
    "href": "STA9750-2025-FALL/lab02.html",
    "title": "Lab 02 Practice",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n#| echo: false\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyverse)\ntxhousing |&gt; \n  filter(city==\"Houston\") |&gt; \n  group_by(year) |&gt; \n  summarize(sales=sum(sales)) |&gt; \n  ggplot(aes(x=year, y=sales)) + \n    geom_line() + \n    ggtitle(\"Annual Houses Sold in Houston, TX\")"
  },
  {
    "objectID": "STA9750-2025-FALL/lab02.html#new-element-two-columns",
    "href": "STA9750-2025-FALL/lab02.html#new-element-two-columns",
    "title": "Lab 02 Practice",
    "section": "NEW ELEMENT — Two Columns",
    "text": "NEW ELEMENT — Two Columns\n\n\n\nNotes\n\nData: txhousing\nCity: Houston\nMetric: yearly sales\n\n\n\n\n\n# A tibble: 6 × 3\n   year sales avg_price\n  &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1  2000 52459   153285.\n2  2001 53856   158590.\n3  2002 56563   167714.\n4  2003 60732   171537.\n5  2004 66979   175822.\n6  2005 72800   185497."
  },
  {
    "objectID": "STA9750-2025-FALL/index.html",
    "href": "STA9750-2025-FALL/index.html",
    "title": "Xiaolin Wu — STA 9750 Website",
    "section": "",
    "text": "Welcome!\nHi, my name is Xiaolin Wu.\nThis website hosts my submission materials for STA 9750 at Baruch College.\nI am currently a graduate student with interests in data analytics and urban design.\nHere, you’ll find my course projects, assignments, and reflections.\n\n📄 My Resume\n\n📧 Contact: xiaolin.wu1@baruchmail.cuny.edu\n\n\n\n\n\n\n\n\nLast Updated: Friday 10 03, 2025 at 01:46AM"
  }
]